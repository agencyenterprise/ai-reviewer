# Can AI Scaling Continue Through 2030? - Epoch AI Report Extract

Sevilla, Jaime, Tamay Besiroglu, Ben Cottier, Josh You, Edu Rold√°n, Pablo Villalobos, and Ege Erdil
Epoch AI, August 20, 2024

## Power as Primary Bottleneck

Power availability has emerged as a primary bottleneck for AI scaling over the next several years. The energy requirements for training cutting-edge AI models are growing at an unprecedented rate.

### Data Center Campus Plans

Multiple AI companies are planning unprecedented multi-gigawatt (GW) campus developments:
- Individual campuses of 1-5 GW by 2030 are in active planning
- These would represent the largest concentrated computing loads ever constructed
- Single facilities approaching 5 GW would rival small state electricity generation capacity

### Grid-Level Constraints

The report identifies several grid-level constraints that may limit AI development:

1. **Infrastructure Expansion**: Current power infrastructure not designed for loads of this magnitude
2. **Timeline Challenges**: Difficulty expanding data center power supply rapidly enough to meet 2030 targets
3. **Geographic Constraints**: Limited number of locations with adequate grid capacity and expansion potential

### Scale Implications

To contextualize the scale: single data center facilities of 1-5 GW by 2030 would represent unprecedented concentrated computing loads, rivaling the total generation capacity of small U.S. states.

The concentration of such massive loads in single locations poses unique challenges for:
- Building necessary infrastructure in a timely manner
- Maintaining grid stability during operations and potential outages
- Securing adequate long-term power supply commitments

## Implications

Power constraints may become the defining limitation on AI model scaling and deployment through 2030, potentially more significant than compute hardware availability or algorithmic improvements.

Source: https://epoch.ai/blog/can-ai-scaling-continue-through-2030
