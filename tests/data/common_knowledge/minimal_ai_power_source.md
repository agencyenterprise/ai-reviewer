# AI Power Consumption - McKinsey Report Extract

Technology, Media & Telecommunications Practice
October 2024

## AI Data Centers and Power Requirements

The race is on to build sufficient data center capacity to support a massive acceleration in the use of AI. Data center demand has already soared in response to the role data plays in modern lives. But with the emergence of generative AI (gen AI), demand is set to rise even higher.

### Power Consumption Trends

Data centers have exploded in size in terms of power consumption. Facilities of approximately 200 MW are now common in the industry. AI-ready data centers require particularly high power densities.

Training large language models like ChatGPT requires significant electrical power:
- Standard AI training racks: 80+ kW per rack
- Nvidia GB200-based training racks: up to 120 kW per rack

### Future Projections

Our analysis of current trends suggests that global demand for data center capacity could rise at an annual rate of between 19 and 22 percent from 2023 to 2030, reaching an annual demand of 171 to 219 gigawatts (GW). A less likely yet still possible scenario sees demand rising by 27 percent to reach 298 GW.

This contrasts with current demand of approximately 55 GW in 2023, representing a potential tripling of global data center power demand by 2030.

### AI-Specific Requirements

The nature of AI workloads is rapidly transforming where and how data centers are being designed and operated. About 70 percent at the midpoint of McKinsey's range of possible scenarios is for data centers equipped to host advanced-AI workloads.

Key factors driving power consumption:
1. The pace of adoption of advanced-AI use cases
2. Mix of different types of chips deployed and their associated power consumption
3. Balance between cloud and edge computing for AI workloads
4. Typical compute, storage, and network needs of AI workloads

Source: Srivathsan, Bhargs, et al. "AI power: Expanding data center capacity to meet growing demand." McKinsey & Company, October 2024.
